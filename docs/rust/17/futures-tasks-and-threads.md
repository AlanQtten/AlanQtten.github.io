# Futures，Tasks和Threads

就像我们在前一章看到的那样，线程提供了一种并发的方法。我们在这一章看到了另一种并发的方法，使用async、future和流。你可能会好奇如何在它们之中进行选择。答案是：视具体情况而定！在很多情况下，我们的选择不是线程*或*async，而是线程*和*async。

很多操作系统在过去的几十年一直在支持基于线程的并发模型，许多编程语言也因此对它们进行了支持。然而，它们并不是完美的。在很多的操作系统下，每个线程都会使用一些内存，这就导致了开启和结束它们会带来额外的性能损耗。且线程也只在你的操作系统和硬件支持的情况下才是一种选择！跟主流的电脑、手机不一样，一些嵌入式系统可能根本没有OS，自然也就没有线程！

async模型提供了一个不同的————但最终会互补的————权衡方案。在async模型中，并发的操作不会要求独立的线程。反之，它们会在任务里运行，就像我们在介绍流时使用`trpl::spawn_task`来开启基于一个异步函数的工作一样。一个任务很像一个线程————但是它不是由操作系统管理，而是由底层的代码管理：也就是运行时。

在前一章，我们看到了如何基于异步通道和开启一个可以运行异步代码的异步任务创造一个`Stream`。我们可以使用线程来完成同样的事！在前面的代码里，我们使用了`trpl::spawn_task`和`trpl::sleep`。而在下面的代码里，我们将其替换为标准库提供的`thread::spwan`和`thread::sleep`API，来实现`get_intervals`函数：

```rust
fn get_intervals() -> impl Stream<Item = u32> {
    let (tx, rx) = trpl::channel();

    // 这里*不是*`trpl::spawn`，而是`std::thread::spawn`！
    thread::spawn(move || {
        let mut count = 0;
        loop {
            // 同样，这里*不是*`trpl::sleep`，而是`std::thread::sleep`！
            thread::sleep(Duration::from_millis(1));
            count += 1;

            if let Err(send_error) = tx.send(count) {
                eprintln!("Could not send interval {count}: {send_error}");
                break;
            }
        }
    });

    ReceiverStream::new(rx)
}
```

如果我们运行这段代码，其输出和之前是完全相同的。你会发现从代码调用的角度来看，做出的改变微乎其微！不仅如此，尽管我们的函数一个开启了async任务，一个开启了OS的线程，但结果的流没有受到任何影响。

然而，这两种实现的行为有一个重要的不同，虽然我们可能很难在这个简单的例子里看出什么区别。但我们可以在现代的电脑上尝试开启成千上万个异步任务。如果我们这么干了，那么内存会被用完！

然而，这些API看起来类似是有原因的。线程是一组同步操作的集合；并发是线程*之间*的可能性。任务是一组异步操作的集合；并发性是任务*之间*和*内部*的可能性。在这方面，任务就像是轻量的、由运行时管理的线程，且因为其受运行时管理而不是操作系统，其功能更多。future就是并发性的最小单元，一个future可能是一棵future树。总结来说，运行时————这里特指管理执行的部分————管理任务，而任务管理future。

然而，这并不意味着async任务比线程更好，也不意味着线程比任务更好。

一方面来说，线程提供的并发性从某种意义上来说比`async`提供的并发性产生的编程模型更简单。线程有点类似于“启动即忘”的方式，它们本身没有与`Future`等价的原生机制，因此它们会一直运行到完成，除非被操作系统中断。因此，它们不存在像future一样的*任务内并发（intra-task concurrency）*。Rust中的线程也没有取消机制————这是我们在本章中未深入探讨的主题，但可以从这样一个事实中隐约看出：每当我们结束一个`Future`时，其状态都会被正确清理。

这些限制使得线程比future更难组合。对于线程来说，构造类似我们之前构造的`timeout`、`throttle`一类的API事非常困难的。而future是更丰满的数据结构，也就是说它们*可以*自然地组合，正如我们看到地一样。

接着，任务会基于future进行额外的控制，允许你选择何时何地对其进行组织。其实线程和任务之间非常和谐，因为任务可以（至少在一些运行时下可以）在线程之间移动。我们目前为止还没有提过，但是底层我们所使用的`Runtime`，包括`spawn_blocking`和`spawn_task`函数，都是天生多线程的！很多运行时会使用一个叫做*工作窃取（work stealing）*的实现，基于各个线程的利用率，隐形地将任务在线程间移动，最终的目的是提供整体系统的性能。要实现这样的功能需要线程*和*任务，当然也少不了future。

所以默认选择它们的思路可以总结为：

- 如果任务*可并行度极高*，比如处理大量的数据，其各个部分可以独立处理，那么线程是更好的选择。
- 如果任务*对并发要求极高*，比如处理不同源发送的，间隔和频率不同的消息，那么async是更好的选择。

如果你同时需要可并行度和并发性，你就不需要在线程和async中进行选择了。你可以自由地一起使用它们，让它们各自的优势发挥到最大。比如，下面的代码展示了一个真实代码中常见的混合使用的例子：

```rust
extern crate trpl; // 为了mdbook的测试

// ANCHOR: all
use std::{thread, time:Duration};

fn main() {
    let (tx, mut rx) = trpl::channel();

    thread::spawn(move || {
        for i in 1..11 {
            tx.send(i).unwrap();
            thread::sleep(Duration::from_secs(1));
        }
    });

    trpl::run(async {
        while let Some(message) = rx.recv().await {
            println!("{message}");
        }
    })
}
// ANCHOR_END: all
```

我们开始创建了一个异步通道。然后我们开启了一个线程，获取了通道发送端的所有权。在线程内，我们发生了数字1到10，在期间延迟了一秒。最终，我们通过传递给`trpl::run`运行了一个异步代码块创建的future，就像本章一直进行的那样。在这个future里，我们等待了那些消息，就像我们见过地其他消息传递的例子一样。

回到本章开头提到的例子：你可以想象用一个专用线程运行一组视频编码任务，因为视频编码是计算密集型的，但可以通过异步通道通知UI这些操作已完成。这类混合使用的例子比比皆是！

## 总结

这不是本书中最后一次涉及并发：第21章里，我们将本章的概念用在更真实的例子里，而不是本章中那些小例子————我们还会直接比较使用线程和使用任务/future解决这类问题的异同。

不管是线程，future和任务，还是它们的组合，Rust都提供了可以写出安全、告诉、可并发的代码————不管是一个高吞吐的网络服务器，还是一个嵌入式系统。

接下来，我们将讨论在Rust程序变得更大时，用惯用方法建模问题和构建解决方案。此外，我们还会探讨Rust的范式与面向对象编程中你可能熟悉的范式之间的关系。
